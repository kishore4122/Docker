Content:
	Load Balancers
	Load Balancing Algorithms
	Proxy Servers: Forward vs Reverse 
	Types of Reverse Proxies
	Nginx & HA Proxy as Reverse Proxy 
	DNS Round robin load balancing

Load Balancers:
***************
	1. Load balancing is the process of distributing network traffic across a group of backend servers, 
		also known as a server farm or server pool.
	2. This ensures no single server bears too much demand/load.
	3. By spreading the load evenly, load balancing improves application  responsiveness.
	4. It also increases availability of applications and websites for users.
	5. Modern applications cannot run without load balancers.


		EndUsers  ---> Internet ----> LoadBalancer ---> Application servers

	6. Modern high-traffic websites must serve hundreds of thousands of concurrent requests from users or 
		clients and return the content or application data, all in a fast and reliable manner.
	7. To meet such high-traffic and volumes of requests, we generally require to adding more servers.
	8. A load balancer acts as the "traffic cop" sitting in front of your servers and 
		routing client requests across all servers capable of fulfilling those requests in a manner 
		that maximizes speed and capacity utilization and ensures that no one server is overworked, 
		which could degrade performance. 
	9. If a single server goes down, the load balancer redirects traffic to the remaining online servers. 
		When a new server is added to the server group, the load balancer automatically starts to send requests to it.

	Load Balancer Uses:
	-------------------
	1. Distributes client requests or network load efficiently across multiple servers
	2. Ensures high availability and reliability by sending requests only to servers that are online
	3. Provides the flexibility to add or subtract servers as demand dictates
	4. Health checks to detect unhealthy instances
	5. Reduced downtime of your application
	6. Seamless Autoscaling (Auto Scaling Group in AWS)
	7. Outage protection. 
	8. Improve load times
	9. Reduce server load 
	10.TLS termination

	Hardware VS Software load balancing
	-----------------------------------
	1. Load balancers typically come in two flavors: hardware-based and software-based.
	2. Vendors of hardware-based solutions load proprietary software onto the machine they provide, 
		which often uses specialized processors. 
		To cope with increasing traffic at your website, you have to buy more or bigger machines from the vendor.
	3. Software LB solutions generally run on hardware, making them less expensive and more flexible. 
		You can install the software on the hardware of your choice or in cloud environments like AWS EC2.

	Cloud Load Balancers
	--------------------
	1. Cloud Load Balancing is a fully distributed, software-defined managed service. 
		It isn't hardware-based, so you don't need to manage a physical load balancing infrastructure.
	2. AWS offers three types of load balancers (ELB), adapted for various scenarios: 
		Classic Load Balancer (Older Layer 4/7), 
		Application Load Balancer (Layer 7), and Network Load Balancer (Layer 4).

	Load Balancing Algorithms:
	**************************
	1. Round Robin 	- Requests are distributed across the group of servers sequentially.
	2. Least Connections - Requests are sent to the backend server with the least number of requests. 
							The relative computing capacity is considered when deciding where the request should be sent
	3. Least Time - Sends requests to the server selected by a formula that combines the fastest response time and 
					fewest active connections. Exclusive to NGINX Plus.
	4. Hash - Distributes requests based on a key you define, such as the client IP address or the request URL. 
				NGINX Plus can optionally apply a consistent hash to minimize redistribution of loads if the set of upstream servers âˆž 
				changes.



Proxy Servers
**************
	1. Proxies are intermediaries between a user and a web server.
	2. Both proxy servers and load balancer are key components of the client-server architecture.
	3. Depending upon the location of the proxy server; user end or server end, it is called Forward or Reverse Proxy

					your IP 					Proxy IP
			You  ------------>  Proxy Server ---------------> Internet


	Reverse Proxy Server
	--------------------
	1. A Reverse Proxy acts as a server for the users.
	2. Each and every request made by a user is directed towards a reverse proxy, 
		thereby acting as an interface for all the servers in the back end.
	3. It receives initial HTTP connection requests, acting like the actual endpoint.


		you -------> Internet -------> Reverse Proxy --------> web server


	Advantages of Reverse Proxy Server
	----------------------------------
	1. A Reverse Proxy hides the topological design of the servers in the background.
	2. Also act as a Cache, which should mean reduced load on the back-end servers.
	3. Makes it easy to log and audit all the requests.
	4. Anonymity and security. Since reverse proxies intercept all the incoming requests, 
		they serve as an additional level of protection for backend servers. 
		It helps prevent any malicious actors from abusing web servers by blocking suspicious traffic from specific IP addresses.
	5. Load balancing. Essentially Load Balancer is one of the applications of a Reverse Proxy



	Forward Proxy Server
	--------------------
	1. A Forward Proxy sits in front of a user and acts as a mediator between users and the web servers they access.
	2. The user's request goes through the forward proxy first and then reaches the web page. 
		Once the data from the server is retrieved, it is sent to the proxy server, redirecting it back to the requester.


							----Internet------------Reverse Proxy--------
							|											|
				You --------|											|-------- Web Serrver
							|											|
							----Forward Proxy-------Internet-------------

	3. From the server's perspective, the request is made by the proxy server itself and not the user.
	4. Forward proxies brings in lot of advantages to organizations, such as universities and enterprises

	Advantages of Forward Proxy Server
	----------------------------------
	1. Block employees/students from visiting certain websites 
	2. Monitor employee online activity
	3. Block malicious traffic from reaching an origin server 
	4. Improve the user experience by caching external site content
	
	Forward VS Reverse Proxy
	------------------------
	1. Forward proxies ensure that websites never communicate directly with a user. 
		On the other hand, Reverse proxies ensure that users would not communicate directly with a back-end server.


-------------------------------------------
Load Balancing
-------------------------------------------

-->with Nginx:
	
	https://superuser.openstack.org/articles/run-load-balanced-service-docker-containers-openstackmic

	Running Containers and Nginx proxy server in Default BRIDGE NETWORK
	-------------------------------------------------------------------

	$docker run -d --name c1  tutum/hello-world			(the application tutum/hello-world exposes on 80:  -p 80:80)
	$docker run -d --name c2  tutum/hello-world
	$docker run -d --name c3  tutum/hello-world

	$docker run -d --name reverse-proxy -p 80:80 nginx

	$docker exec -it reverse-proxy /bin/bash

	#Change the config file /etc/nginx/conf.d/default.conf and add the below content.
	#Copy the IPAddresses of each container and paste them below

	upstream servers {
	server 15.206.89.202:8080;		# IP addresses of the container we run above
	server 15.206.89.202:8081;
	server 15.206.89.202:8082;
	}

	#This server accepts all traffic to the port 80 and passes it to the upstream
	#Notice that the upstream name and the proxy_pass need to match

	server {
	listen  80;

	location / {
	proxy_pass http://servers;
	}
	}

	$docker restart reverse-proxy
	Access the application.


	Running Containers and Nginx proxy server in CUSTOM BRIDGE NETWORK 
	*******************************************************************
	#Create a Custom Bridge Network
		$docker network create my-net

	$docker run -d --net my-net --name c1  tutum/hello-world	(the application tutum/hello-world exposes on 80:  -p 80:80)
	$docker run -d --net my-net --name c2  tutum/hello-world
	$docker run -d --net my-net --name c3  tutum/hello-world

	$docker run -d --net my-net --name reverse-proxy -p 80:80 nginx

	$docker exec -it reverse-proxy /bin/bash

	#Change the config file /etc/nginx/conf.d/default.conf and add the below content.
	#Copy the IPAddresses of each container and paste them below

	upstream servers {
	server c1;
	server c2;
	server c3;
	}

	#This server accepts all traffic to the port 80 and passes it to the upstream
	#Notice that the upstream name and the proxy_pass need to match

	server {
	listen  80;

	location / {
	proxy_pass http://servers;
	}
	}

	$docker restart reverse-proxy
	Access the application.



--> With HAPProxy:

	HA Proxy: https://www.haproxy.com/blog/haproxy-configuration-basics-load-balance-your-servers/; 
				https://hub.docker.com/r/haproxytech/haproxy-ubuntu

	#Create Custom Bridge network
		$docker network create my_net

	$docker run -d --net my_net -p 80:80 --name haproxy -v haproxy:/usr/local/etc/haproxy: ro haproxytech/haproxy-ubuntu:2.0
	
	$docker run -d --net my_net --name c1 kunchalavikram/hello-flask:v1 		(the application is running on port 5000:  -p 80:5000)
	$docker run -d --net my_net --name c2 kunchalavikram/hello-flask:v1 
	$docker run -d --net my_net --name c3 kunchalavikram/hello-flask:v1


	# As we bind the volume to the host machine now we can able to change the configuration of haproxy in our local machine 
		by going into
		the /var/lib/docker/volumes/haproxy/_data/haproxy.cfg
		Now in round robin balancing replace the IPAddress with container names because we are running the HAPROXY and CONTAINERS
		in a CUSTOM BRIDGE NETWORK (my_net)
	#---------------------------------------------------------------------
	# main frontend which proxys to the backends
	#---------------------------------------------------------------------
	frontend  main
    	bind *:80
    	# bind *:443 ssl # To be completed ....

    	acl url_static       path_beg       -i /static /images /javascript /stylesheets
    	acl url_static       path_end       -i .jpg .gif .png .css .js

    	use_backend static          if url_static
    	default_backend             app

	#---------------------------------------------------------------------
	# static backend for serving up images, stylesheets and such
	#---------------------------------------------------------------------
	backend static
    	balance     roundrobin
    	server      static1 127.0.0.1:4331 check
    	server      static2 127.0.0.1:4332 check

	#---------------------------------------------------------------------
	# round robin balancing between the various backends
	#---------------------------------------------------------------------
	backend app
    	balance     roundrobin
    	server  app1 c1:5000 check
    	server  app2 c2:5000 check
    	server  app3 c3:5000 check
    	server  app4 c4:5000 check


	* All containers are running on 5000
	#Now restart the haproxy container 
		$docker restart haproxy
	




DNS Round Robin (--net-alias)
*****************************
	1. DNS round robin is one of load balancing approaches.
	2. With DNS round robin, we rely on the DNS server responses.
	3. DNS servers respond to DNS requests not only with a single IP address 
		but with one out of a list of possible IP addresses of containers that host the same services.
	4. In docker, this is made possible by Embedded DNS Server for containers in user-defined networks since Docker 1.10.
	5. In particular, containers that are run with a network alias (--net-alias) are resolved 
		by this embedded DNS with the IP address of the container when the alias is used.



	$docker run -d --net my_net --name c1 --net-alias web kunchalavikram/hello-flask: v1 
	$docker run -d --net my_net --name c2 --net-alias web kunchalavikram/hello-flask: v1 
	$docker run -d --net my_net --name c3 --net-alias web kunchalavikram/hello-flask: v1
	$docker run --rm --net my net curlimages/curl -s web: 5000

